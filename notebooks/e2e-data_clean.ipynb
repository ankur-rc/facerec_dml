{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Procedure: Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Outline\n",
    "1. Filter the dataset ***<--- This notebook***\n",
    "    - Detect faces among all the images. Reject images that have more than one face, or no face.\n",
    "    - Save filtered dataset to new location.\n",
    "2. Generate Train-Test Splits ***<--- This notebook***\n",
    "    - Create folds.\n",
    "3. Evaluate \n",
    "    - Generate embeddings from the splits\n",
    "    - Train classifier on the embeddings\n",
    "    - Test classifier on the embeddings\n",
    "4. Tune classifier\n",
    "    - Tune the classifier \n",
    "5. Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pprint\n",
    "import logging\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "import face_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_trigger.model.deep.FaceRecognizer import FaceRecognizer\n",
    "from face_trigger.process.post_process import FaceDetector, LandmarkDetector, FaceAlign\n",
    "from face_trigger.utils.common import RepeatedTimer, clamp_rectangle\n",
    "from face_trigger.utils.data import dataset_filter, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_dataset_path = \"/media/ankurrc/new_volume/softura/facerec/datasets/softura_emp\"\n",
    "dataset_path = \"/media/ankurrc/new_volume/softura/facerec/softura_filtered\"\n",
    "split_path = \"/media/ankurrc/new_volume/softura/facerec/softura_split_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset\n",
    " **Note:** While filtering the dataset we assume that the original dataset has the following structure:\n",
    " 1. At the root level there are directories that represent each personality. The directories may or may not have a numeric name.\n",
    " 2. Within each directory, the files should represent the images that contain the parent directory's(personality) faces. The file names may or may not be numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_the_dataset(unnormalized_dataset_path=None, dataset_path=None):\n",
    "    return dataset_filter(dataset_path=unnormalized_dataset_path, output_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:45<00:00,  2.23s/it]\n",
      "INFO:face_trigger.utils.data:Filtered dataset created at /media/ankurrc/new_volume/softura/facerec/softura_filtered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected directories:\n",
      "{'20': ['IMG_0093.jpg']}\n"
     ]
    }
   ],
   "source": [
    "rejected_dirs = filter_the_dataset(unnormalized_dataset_path=unnormalized_dataset_path, dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Splits (Optional)\n",
    "**Note:** Generating manual splits is optional. In the training section, we use sklearn's cv.\n",
    "  If you decide to use manual-splitting, you need to change the training routine as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(dataset_path=None, split_path=None):\n",
    "    dataset = Dataset(dataset_path=dataset_path,\n",
    "                      split_path=split_path)\n",
    "    folds = 3\n",
    "    training_samples = [2, 5, 8]\n",
    "    \n",
    "    dataset.split(num_train_list=training_samples, folds=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:face_trigger.utils.data:Generating for 2 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/3/train.csv\n",
      "INFO:face_trigger.utils.data:We have 40 subjects in our dataset.\n",
      "INFO:face_trigger.utils.data:Generating for 5 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/3/train.csv\n",
      "INFO:face_trigger.utils.data:We have 40 subjects in our dataset.\n",
      "INFO:face_trigger.utils.data:Generating for 8 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/3/train.csv\n",
      "INFO:face_trigger.utils.data:The following directories were rejected: ['37']\n",
      "INFO:face_trigger.utils.data:We have 39 subjects in our dataset.\n"
     ]
    }
   ],
   "source": [
    "generate_splits(dataset_path=dataset_path, split_path=split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment dataset by jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum samples for each class\n",
    "k_core = 10\n",
    "\n",
    "X_oversampled = []\n",
    "y_oversampled = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    \n",
    "    for direc in dirs:\n",
    "            person_id = direc\n",
    "            count_dict[person_id] = None\n",
    "                    \n",
    "    if root != dataset_path:\n",
    "        count_dict[os.path.split(root)[1]] = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which classes have a count less than k_core\n",
    "minority_classes = []\n",
    "for key, val in count_dict.items():\n",
    "    if val < k_core:\n",
    "        minority_classes.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minority_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4200bb050931>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples_required\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminority_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mX_oversampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my_oversampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_enc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'minority_indices' is not defined"
     ]
    }
   ],
   "source": [
    "# randomly resample for each minority class\n",
    "for minority in minority_classes:\n",
    "    # num of samples our minority class has\n",
    "    sample_count = count_dict[minority]\n",
    "    # num of samples required to make it k-core\n",
    "    samples_required = k_core - sample_count\n",
    "    # minority class' filenames\n",
    "    minority_files = os.listdir(os.path.join(dataset_path, minority))\n",
    "    jitters_per_sample = int(math.ceil(samples_required/sample_count))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps 3, 4 and 5 are in another notebook - End-to-End: Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (dl2)",
   "language": "python",
   "name": "dl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
