{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Procedure: Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Outline\n",
    "1. Filter the dataset ***<--- This notebook***\n",
    "    - Detect faces among all the images. Reject images that have more than one face, or no face.\n",
    "    - Save filtered dataset to new location.\n",
    "2. Generate Train-Test Splits ***<--- This notebook***\n",
    "    - Create folds.\n",
    "3. Evaluate \n",
    "    - Generate embeddings from the splits\n",
    "    - Train classifier on the embeddings\n",
    "    - Test classifier on the embeddings\n",
    "4. Tune classifier\n",
    "    - Tune the classifier \n",
    "5. Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pprint\n",
    "import logging\n",
    "import tqdm\n",
    "import math\n",
    "\n",
    "import face_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_trigger.model.deep.FaceRecognizer import FaceRecognizer\n",
    "from face_trigger.process.post_process import FaceDetector, LandmarkDetector, FaceAlign\n",
    "from face_trigger.utils.common import RepeatedTimer, clamp_rectangle\n",
    "from face_trigger.utils.data import dataset_filter, Dataset, get_jittered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_dataset_path = \"/media/ankurrc/new_volume/softura/facerec/datasets/softura_emp\"\n",
    "dataset_path = \"/media/ankurrc/new_volume/softura/facerec/softura_filtered\"\n",
    "split_path = \"/media/ankurrc/new_volume/softura/facerec/softura_split_path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset\n",
    " **Note:** While filtering the dataset we assume that the original dataset has the following structure:\n",
    " 1. At the root level there are directories that represent each personality. The directories may or may not have a numeric name.\n",
    " 2. Within each directory, the files should represent the images that contain the parent directory's(personality) faces. The file names may or may not be numeric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_the_dataset(unnormalized_dataset_path=None, dataset_path=None):\n",
    "    return dataset_filter(dataset_path=unnormalized_dataset_path, output_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [01:51<00:00,  2.06s/it]\n",
      "INFO:face_trigger.utils.data:Filtered dataset created at /media/ankurrc/new_volume/softura/facerec/softura_filtered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rejected files:\n",
      "{'20': [{'img': 'IMG_0093.jpg', 'reason': 'faces detected: 2'},\n",
      "        {'img': 'IMG_0095.jpg', 'reason': 'faces detected: 2'}]}\n"
     ]
    }
   ],
   "source": [
    "rejected_dirs = filter_the_dataset(unnormalized_dataset_path=unnormalized_dataset_path, dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dict = {}\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    \n",
    "    for direc in dirs:\n",
    "            person_id = direc\n",
    "            count_dict[person_id] = None\n",
    "                    \n",
    "    if root != dataset_path:\n",
    "        count_dict[os.path.split(root)[1]] = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following directories were empty, and were removed: []\n"
     ]
    }
   ],
   "source": [
    "empty_dir = []\n",
    "for key, val in count_dict.iteritems():\n",
    "    if val == 0:\n",
    "        directory = os.path.join(dataset_path, key)\n",
    "        os.rmdir(directory)\n",
    "        empty_dir.append(key)\n",
    "\n",
    "print(\"The following directories were empty, and were removed: {}\".format(empty_dir))\n",
    "\n",
    "for direc in empty_dir:\n",
    "    count_dict.pop(direc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Splits (Optional)\n",
    "**Note:** Generating manual splits is optional. In the training section, we use sklearn's cv.\n",
    "  If you decide to use manual-splitting, you need to change the training routine as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(dataset_path=None, split_path=None):\n",
    "    dataset = Dataset(dataset_path=dataset_path,\n",
    "                      split_path=split_path)\n",
    "    folds = 3\n",
    "    training_samples = [2, 5, 8]\n",
    "    \n",
    "    dataset.split(num_train_list=training_samples, folds=folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:face_trigger.utils.data:Generating for 2 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/2/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/2/3/train.csv\n",
      "INFO:face_trigger.utils.data:We have 40 subjects in our dataset.\n",
      "INFO:face_trigger.utils.data:Generating for 5 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/5/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/5/3/train.csv\n",
      "INFO:face_trigger.utils.data:We have 40 subjects in our dataset.\n",
      "INFO:face_trigger.utils.data:Generating for 8 training samples per subject.\n",
      "INFO:face_trigger.utils.data:Generating: Fold 1\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/1\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/1/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 2\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/2\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/2/train.csv\n",
      "INFO:face_trigger.utils.data:Generating: Fold 3\n",
      "INFO:face_trigger.utils.data:Creating directory: /media/ankurrc/new_volume/softura/facerec/att_split_path/8/3\n",
      "INFO:face_trigger.utils.data:done.\n",
      "INFO:face_trigger.utils.data:/media/ankurrc/new_volume/softura/facerec/att_split_path/8/3/train.csv\n",
      "INFO:face_trigger.utils.data:The following directories were rejected: ['37']\n",
      "INFO:face_trigger.utils.data:We have 39 subjects in our dataset.\n"
     ]
    }
   ],
   "source": [
    "generate_splits(dataset_path=dataset_path, split_path=split_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment dataset by jittering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum samples for each class\n",
    "k_core = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which classes have a count less than k_core\n",
    "minority_classes = []\n",
    "for key, val in count_dict.items():\n",
    "    if val < k_core:\n",
    "        minority_classes.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '28',\n",
       " '29',\n",
       " '40',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '5',\n",
       " '4',\n",
       " '7',\n",
       " '6',\n",
       " '9',\n",
       " '8',\n",
       " '39',\n",
       " '11',\n",
       " '10',\n",
       " '13',\n",
       " '14',\n",
       " '17',\n",
       " '16',\n",
       " '19',\n",
       " '18',\n",
       " '31',\n",
       " '30',\n",
       " '37',\n",
       " '36',\n",
       " '35',\n",
       " '34',\n",
       " '33',\n",
       " '32']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37 [00:00<?, ?it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.40s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.39s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.49s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\u001b[A\n",
      "  3%|▎         | 1/37 [00:06<03:44,  6.24s/it]\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█▎        | 1/8 [00:01<00:11,  1.67s/it]\u001b[A\n",
      " 25%|██▌       | 2/8 [00:03<00:09,  1.55s/it]\u001b[A\n",
      " 38%|███▊      | 3/8 [00:04<00:06,  1.40s/it]\u001b[A\n",
      " 50%|█████     | 4/8 [00:05<00:05,  1.39s/it]\u001b[A\n",
      " 62%|██████▎   | 5/8 [00:06<00:04,  1.38s/it]\u001b[A\n",
      " 75%|███████▌  | 6/8 [00:08<00:02,  1.38s/it]\u001b[A\n",
      " 88%|████████▊ | 7/8 [00:09<00:01,  1.38s/it]\u001b[A\n",
      "100%|██████████| 8/8 [00:10<00:00,  1.37s/it]\u001b[A\n",
      "  5%|▌         | 2/37 [00:17<05:01,  8.61s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.17s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.27s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\u001b[A\n",
      "  8%|▊         | 3/37 [00:22<04:14,  7.50s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.31s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\u001b[A\n",
      " 11%|█         | 4/37 [00:27<03:49,  6.96s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:00<00:03,  1.05it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.09s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.14s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\u001b[A\n",
      " 14%|█▎        | 5/37 [00:34<03:38,  6.82s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.43s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.35s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.33s/it]\u001b[A\n",
      " 16%|█▌        | 6/37 [00:39<03:23,  6.58s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.25s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.27s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:05<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\u001b[A\n",
      " 19%|█▉        | 7/37 [00:45<03:16,  6.55s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.36s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.38s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.39s/it]\u001b[A\n",
      " 22%|██▏       | 8/37 [00:51<03:06,  6.42s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.37s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.37s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.38s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.34s/it]\u001b[A\n",
      " 24%|██▍       | 9/37 [00:56<02:56,  6.31s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:02<00:09,  2.38s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:03<00:05,  1.83s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:05<00:03,  1.73s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:06<00:01,  1.62s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:07<00:00,  1.58s/it]\u001b[A\n",
      " 27%|██▋       | 10/37 [01:04<02:54,  6.46s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.36s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.42s/it]\u001b[A\n",
      " 30%|██▉       | 11/37 [01:07<02:39,  6.14s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.22s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.20s/it]\u001b[A\n",
      " 32%|███▏      | 12/37 [01:11<02:28,  5.93s/it]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.35s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.21s/it]\u001b[A\n",
      " 35%|███▌      | 13/37 [01:14<02:18,  5.75s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:08,  1.36s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.34s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:05,  1.28s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:03,  1.30s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:06<00:02,  1.38s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:08<00:01,  1.37s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:09<00:00,  1.35s/it]\u001b[A\n",
      " 38%|███▊      | 14/37 [01:24<02:18,  6.02s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.29s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\u001b[A\n",
      " 41%|████      | 15/37 [01:26<02:07,  5.80s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.39s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.30s/it]\u001b[A\n",
      " 43%|████▎     | 16/37 [01:32<02:00,  5.76s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.22s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.27s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.25s/it]\u001b[A\n",
      " 46%|████▌     | 17/37 [01:37<01:54,  5.72s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.18s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:03<00:03,  1.15s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:04<00:02,  1.16s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:06<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\u001b[A\n",
      " 49%|████▊     | 18/37 [01:44<01:50,  5.81s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.39s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.32s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.35s/it]\u001b[A\n",
      " 51%|█████▏    | 19/37 [01:49<01:44,  5.79s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:05,  1.32s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.25s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.30s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:05<00:01,  1.28s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\u001b[A\n",
      " 54%|█████▍    | 20/37 [01:56<01:38,  5.82s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.30s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\u001b[A\n",
      " 57%|█████▋    | 21/37 [02:01<01:32,  5.79s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.14s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.72s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.62s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\u001b[A\n",
      " 59%|█████▉    | 22/37 [02:07<01:27,  5.81s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.14s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.21s/it]\u001b[A\n",
      " 62%|██████▏   | 23/37 [02:12<01:20,  5.77s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:05,  1.30s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.30s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.24s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.25s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.25s/it]\u001b[A\n",
      " 65%|██████▍   | 24/37 [02:18<01:15,  5.79s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.24s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.30s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.22s/it]\u001b[A\n",
      " 68%|██████▊   | 25/37 [02:23<01:09,  5.76s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:01<00:05,  1.17s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:02<00:04,  1.21s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:03<00:03,  1.21s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:04<00:02,  1.19s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:06<00:01,  1.21s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\u001b[A\n",
      " 70%|███████   | 26/37 [02:31<01:03,  5.81s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.28s/it]\u001b[A\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.33s/it]\u001b[A\n",
      " 73%|███████▎  | 27/37 [02:33<00:56,  5.70s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.05s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.13s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.17s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.18s/it]\u001b[A\n",
      " 76%|███████▌  | 28/37 [02:38<00:50,  5.66s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.27s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.12s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.15s/it]\u001b[A\n",
      " 78%|███████▊  | 29/37 [02:43<00:44,  5.62s/it]\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\n",
      " 14%|█▍        | 1/7 [00:01<00:07,  1.29s/it]\u001b[A\n",
      " 29%|██▊       | 2/7 [00:02<00:06,  1.34s/it]\u001b[A\n",
      " 43%|████▎     | 3/7 [00:03<00:05,  1.31s/it]\u001b[A\n",
      " 57%|█████▋    | 4/7 [00:05<00:04,  1.48s/it]\u001b[A\n",
      " 71%|███████▏  | 5/7 [00:07<00:02,  1.48s/it]\u001b[A\n",
      " 86%|████████▌ | 6/7 [00:08<00:01,  1.46s/it]\u001b[A\n",
      "100%|██████████| 7/7 [00:10<00:00,  1.45s/it]\u001b[A\n",
      " 81%|████████  | 30/37 [02:53<00:40,  5.78s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.46s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.46s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.42s/it]\u001b[A\n",
      " 84%|████████▍ | 31/37 [02:58<00:34,  5.77s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.44s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.43s/it]\u001b[A\n",
      " 86%|████████▋ | 32/37 [03:04<00:28,  5.77s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.37s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.36s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.38s/it]\u001b[A\n",
      " 89%|████████▉ | 33/37 [03:10<00:23,  5.76s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.58s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.46s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:04<00:01,  1.44s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.44s/it]\u001b[A\n",
      " 92%|█████████▏| 34/37 [03:15<00:17,  5.76s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.23s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.25s/it]\u001b[A\n",
      " 95%|█████████▍| 35/37 [03:21<00:11,  5.74s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:05,  1.43s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:04,  1.41s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:04<00:02,  1.37s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:05<00:01,  1.37s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.39s/it]\u001b[A\n",
      " 97%|█████████▋| 36/37 [03:27<00:05,  5.78s/it]\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A\n",
      " 17%|█▋        | 1/6 [00:01<00:05,  1.18s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [00:03<00:07,  1.80s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [00:04<00:04,  1.60s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [00:06<00:03,  1.56s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [00:07<00:01,  1.51s/it]\u001b[A\n",
      "100%|██████████| 6/6 [00:08<00:00,  1.48s/it]\u001b[A\n",
      "100%|██████████| 37/37 [03:36<00:00,  5.86s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm.trange(len(minority_classes)):\n",
    "    minority = minority_classes[idx]\n",
    "    # num of samples our minority class has\n",
    "    sample_count = count_dict[minority]\n",
    "    # num of samples required to make it k-core\n",
    "    samples_required = k_core - sample_count\n",
    "    # minority class' filenames\n",
    "    minority_files = os.listdir(os.path.join(dataset_path, minority))\n",
    "    jitters_per_sample = int(math.ceil(samples_required/sample_count))\n",
    "    \n",
    "    for file_idx in tqdm.trange(len(minority_files)):\n",
    "        fil = minority_files[file_idx]\n",
    "        file_path = os.path.join(dataset_path, minority, fil)\n",
    "        jittered_images = get_jittered_images(file_path, num_jitters=jitters_per_sample, disturb_colors=True)\n",
    "        \n",
    "        for i, jittered_image in enumerate(jittered_images): \n",
    "            file_name = fil + \"_jittered_\" + str(i) + \".jpg\"\n",
    "            save_path = os.path.join(dataset_path, minority, file_name)\n",
    "            ret = cv2.imwrite(save_path, jittered_image)\n",
    "            if ret is False:\n",
    "                raise Exception(\"Failed to write file:{}\".format(save_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 12,\n",
       " '10': 12,\n",
       " '11': 12,\n",
       " '12': 12,\n",
       " '13': 10,\n",
       " '14': 12,\n",
       " '16': 10,\n",
       " '17': 12,\n",
       " '18': 12,\n",
       " '19': 12,\n",
       " '2': 14,\n",
       " '20': 10,\n",
       " '21': 12,\n",
       " '22': 10,\n",
       " '23': 12,\n",
       " '24': 12,\n",
       " '25': 16,\n",
       " '26': 12,\n",
       " '27': 12,\n",
       " '28': 12,\n",
       " '29': 10,\n",
       " '3': 12,\n",
       " '30': 12,\n",
       " '31': 14,\n",
       " '32': 12,\n",
       " '33': 10,\n",
       " '34': 12,\n",
       " '35': 12,\n",
       " '36': 12,\n",
       " '37': 12,\n",
       " '38': 10,\n",
       " '39': 12,\n",
       " '4': 12,\n",
       " '40': 10,\n",
       " '41': 28,\n",
       " '5': 10,\n",
       " '6': 12,\n",
       " '7': 12,\n",
       " '8': 10,\n",
       " '9': 12}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_dict = {}\n",
    "for root, dirs, files in os.walk(dataset_path):\n",
    "    \n",
    "    for direc in dirs:\n",
    "            person_id = direc\n",
    "            count_dict[person_id] = None\n",
    "                    \n",
    "    if root != dataset_path:\n",
    "        count_dict[os.path.split(root)[1]] = len(files)\n",
    "        \n",
    "count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps 3, 4 and 5 are in another notebook - End-to-End: Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (dl2)",
   "language": "python",
   "name": "dl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
