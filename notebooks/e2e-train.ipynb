{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End-to-End: Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedure Outline\n",
    "1. Filter the dataset \n",
    "    - Detect faces among all the images. Reject images that have more than one face, or no face.\n",
    "    - Save filtered dataset to new location.\n",
    "2. Generate Train-Test Splits\n",
    "    - Create folds.\n",
    "3. Evaluate ***<--- This notebook***\n",
    "    - Generate embeddings from the splits\n",
    "    - Train classifier on the embeddings\n",
    "    - Test classifier on the embeddings\n",
    "4. Tune classifier ***<--- This notebook***\n",
    "    - Tune the classifier \n",
    "5. Save the model ***<--- This notebook***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import logging\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import face_trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_trigger.utils.train import generate_embeddings_for_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/media/ankurrc/new_volume/softura/facerec/softura_filtered/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the embeddings for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(dataset_path=None):\n",
    "    return generate_embeddings_for_dataset(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]DEBUG:face_trigger.model.deep.FaceRecognizer:No DNN model path specified, using default.\n",
      "WARNING:face_trigger.model.deep.FaceRecognizer:Classifier model path not given.\n",
      "WARNING:face_trigger.model.deep.FaceRecognizer:No label mapping provided!\n",
      "100%|██████████| 40/40 [01:54<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "X, y = get_embeddings(dataset_path=dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "y_arr = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "X_arr = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize embeddings (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_file_path = \"/media/ankurrc/new_volume/softura/facerec/embeddings/x.tsv\"\n",
    "y_file_path = \"/media/ankurrc/new_volume/softura/facerec/embeddings/y.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(x_file_path, X_arr, delimiter='\\t')\n",
    "np.savetxt(y_file_path, y_arr, fmt=\"%s\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project the embeddings\n",
    "Load the generated files as data('x_file_path') and metadata('y_file_path') on http://projector.tensorflow.org/ to project the embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "classes = np.unique(y_arr)\n",
    "encoder.fit(classes)\n",
    "# transform our ground truth\n",
    "y_enc = encoder.transform(y_arr)\n",
    "# get a mapping to use later\n",
    "encoder_mapping = dict(zip(encoder.transform(classes),encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1',\n",
       " 1: '10',\n",
       " 2: '11',\n",
       " 3: '12',\n",
       " 4: '13',\n",
       " 5: '14',\n",
       " 6: '16',\n",
       " 7: '17',\n",
       " 8: '18',\n",
       " 9: '19',\n",
       " 10: '2',\n",
       " 11: '20',\n",
       " 12: '21',\n",
       " 13: '22',\n",
       " 14: '23',\n",
       " 15: '24',\n",
       " 16: '25',\n",
       " 17: '26',\n",
       " 18: '27',\n",
       " 19: '28',\n",
       " 20: '29',\n",
       " 21: '3',\n",
       " 22: '30',\n",
       " 23: '31',\n",
       " 24: '32',\n",
       " 25: '33',\n",
       " 26: '34',\n",
       " 27: '35',\n",
       " 28: '36',\n",
       " 29: '37',\n",
       " 30: '38',\n",
       " 31: '39',\n",
       " 32: '4',\n",
       " 33: '40',\n",
       " 34: '41',\n",
       " 35: '5',\n",
       " 36: '6',\n",
       " 37: '7',\n",
       " 38: '8',\n",
       " 39: '9'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversample categories if required\n",
    "\n",
    "We use random-resampling for minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum samples for each class\n",
    "k_core = 10\n",
    "\n",
    "X_oversampled = []\n",
    "y_oversampled = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category counts\n",
    "y_counts = Counter(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 12,\n",
       "         1: 12,\n",
       "         2: 12,\n",
       "         3: 12,\n",
       "         4: 10,\n",
       "         5: 12,\n",
       "         6: 10,\n",
       "         7: 12,\n",
       "         8: 12,\n",
       "         9: 12,\n",
       "         10: 14,\n",
       "         11: 10,\n",
       "         12: 12,\n",
       "         13: 10,\n",
       "         14: 12,\n",
       "         15: 12,\n",
       "         16: 16,\n",
       "         17: 12,\n",
       "         18: 12,\n",
       "         19: 12,\n",
       "         20: 10,\n",
       "         21: 12,\n",
       "         22: 12,\n",
       "         23: 14,\n",
       "         24: 12,\n",
       "         25: 10,\n",
       "         26: 12,\n",
       "         27: 12,\n",
       "         28: 12,\n",
       "         29: 12,\n",
       "         30: 10,\n",
       "         31: 12,\n",
       "         32: 12,\n",
       "         33: 10,\n",
       "         34: 28,\n",
       "         35: 10,\n",
       "         36: 12,\n",
       "         37: 12,\n",
       "         38: 10,\n",
       "         39: 10})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which classes have a count less than k_core\n",
    "minority_classes = []\n",
    "for key, val in y_counts.items():\n",
    "    if val < k_core:\n",
    "        minority_classes.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly resample for each minority class\n",
    "for minority in minority_classes:\n",
    "    # num of samples our minority class has\n",
    "    minority_count = y_counts[minority]\n",
    "    # num of samples required to make it k-core\n",
    "    samples_required = k_core - minority_count\n",
    "    # minority class' indices\n",
    "    minority_indices = np.argwhere((y_enc == minority)).flatten()\n",
    "\n",
    "    # loop till we have added enough samples\n",
    "    for i in range(samples_required):\n",
    "        random.Random().shuffle(minority_indices)\n",
    "        index = minority_indices[0]\n",
    "        X_oversampled.append(X_arr[index])\n",
    "        y_oversampled.append(y_enc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "X_oversampled = np.array(X_oversampled)\n",
    "y_oversampled = np.array(y_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate both our original array and resampled minority ones to obtain a k-core dataset\n",
    "if X_oversampled.shape[0] > 0:\n",
    "    X_total = np.concatenate((X_arr, X_oversampled), axis=0)\n",
    "    y_toal = np.concatenate((y_enc, y_oversampled), axis=0)\n",
    "else:\n",
    "    X_total = X_arr\n",
    "    y_total = y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_total.shape[1] == 128\n",
    "assert X_total.shape[0] == y_total.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all hyperparameter knobs here\n",
    "dual = True # set false for datasets that have num_dims > num_samples\n",
    "class_weight = \"balanced\" # set for class imbalance\n",
    "Cs = np.logspace(-3, 3, 7, base=10.0)\n",
    "n_jobs = cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameter grid\n",
    "param_grid = dict(base_estimator__C=Cs)\n",
    "# setup cross-validation strategy\n",
    "cv = StratifiedShuffleSplit(n_splits=3,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup classifier\n",
    "svm = LinearSVC(dual=dual,class_weight=class_weight)\n",
    "# we need probabilities, so we use a calibrated classifier\n",
    "clf = CalibratedClassifierCV(svm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup our grid-search object\n",
    "grid = GridSearchCV(clf, param_grid=param_grid, cv=cv, verbose=True, n_jobs=n_jobs, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  21 out of  21 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=3, random_state=42, test_size=0.2,\n",
       "            train_size=None),\n",
       "       error_score='raise',\n",
       "       estimator=CalibratedClassifierCV(base_estimator=LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "            cv=3, method='sigmoid'),\n",
       "       fit_params=None, iid=True, n_jobs=4,\n",
       "       param_grid={'base_estimator__C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the data\n",
    "grid.fit(X_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'base_estimator__C': 10.0} with a score of 1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters are {0:s} with a score of {1:0.2f}\".format(grid.best_params_, grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_base_estimator__C</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.035603</td>\n",
       "      <td>0.026554</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.135931</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{u'base_estimator__C': 0.001}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.135065</td>\n",
       "      <td>0.134021</td>\n",
       "      <td>0.153247</td>\n",
       "      <td>0.145223</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.909461</td>\n",
       "      <td>0.029253</td>\n",
       "      <td>0.924399</td>\n",
       "      <td>0.928139</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{u'base_estimator__C': 0.01}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.932468</td>\n",
       "      <td>0.907216</td>\n",
       "      <td>0.932468</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.919481</td>\n",
       "      <td>0.058705</td>\n",
       "      <td>0.022121</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>0.006122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.960495</td>\n",
       "      <td>0.030457</td>\n",
       "      <td>0.955326</td>\n",
       "      <td>0.966234</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{u'base_estimator__C': 0.1}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.948454</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.958763</td>\n",
       "      <td>0.953247</td>\n",
       "      <td>0.078059</td>\n",
       "      <td>0.017008</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.009244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.213510</td>\n",
       "      <td>0.018982</td>\n",
       "      <td>0.986254</td>\n",
       "      <td>0.988745</td>\n",
       "      <td>1</td>\n",
       "      <td>{u'base_estimator__C': 1.0}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.969072</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989610</td>\n",
       "      <td>0.989691</td>\n",
       "      <td>0.989610</td>\n",
       "      <td>0.052523</td>\n",
       "      <td>0.007539</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.646430</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'base_estimator__C': 10.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.003860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.212373</td>\n",
       "      <td>0.015418</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'base_estimator__C': 100.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.807460</td>\n",
       "      <td>0.011239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1000</td>\n",
       "      <td>{u'base_estimator__C': 1000.0}</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269827</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       1.035603         0.026554         0.134021          0.135931   \n",
       "1       0.909461         0.029253         0.924399          0.928139   \n",
       "2       0.960495         0.030457         0.955326          0.966234   \n",
       "3       1.213510         0.018982         0.986254          0.988745   \n",
       "4       1.646430         0.015985         1.000000          1.000000   \n",
       "5       2.212373         0.015418         1.000000          1.000000   \n",
       "6       1.807460         0.011239         1.000000          1.000000   \n",
       "\n",
       "  param_base_estimator__C                          params  rank_test_score  \\\n",
       "0                   0.001   {u'base_estimator__C': 0.001}                7   \n",
       "1                    0.01    {u'base_estimator__C': 0.01}                6   \n",
       "2                     0.1     {u'base_estimator__C': 0.1}                5   \n",
       "3                       1     {u'base_estimator__C': 1.0}                4   \n",
       "4                      10    {u'base_estimator__C': 10.0}                1   \n",
       "5                     100   {u'base_estimator__C': 100.0}                1   \n",
       "6                    1000  {u'base_estimator__C': 1000.0}                1   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.134021            0.119481           0.134021   \n",
       "1           0.938144            0.932468           0.907216   \n",
       "2           0.948454            0.974026           0.958763   \n",
       "3           0.969072            0.987013           1.000000   \n",
       "4           1.000000            1.000000           1.000000   \n",
       "5           1.000000            1.000000           1.000000   \n",
       "6           1.000000            1.000000           1.000000   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.135065           0.134021            0.153247      0.145223   \n",
       "1            0.932468           0.927835            0.919481      0.058705   \n",
       "2            0.971429           0.958763            0.953247      0.078059   \n",
       "3            0.989610           0.989691            0.989610      0.052523   \n",
       "4            1.000000           1.000000            1.000000      0.092530   \n",
       "5            1.000000           1.000000            1.000000      0.063996   \n",
       "6            1.000000           1.000000            1.000000      0.269827   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.007725        0.000000         0.013799  \n",
       "1        0.022121        0.012858         0.006122  \n",
       "2        0.017008        0.004860         0.009244  \n",
       "3        0.007539        0.012858         0.001224  \n",
       "4        0.003860        0.000000         0.000000  \n",
       "5        0.010137        0.000000         0.000000  \n",
       "6        0.006685        0.000000         0.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results = pd.DataFrame(data=grid.cv_results_)\n",
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save paths \n",
    "save_path = \"/media/ankurrc/new_volume/softura/facerec/softura_trained\"\n",
    "clf_name = \"classifier.pkl\"\n",
    "label_map_file = \"label_mapping.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ankurrc/new_volume/softura/facerec/softura_trained/classifier.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid, os.path.join(save_path, clf_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/ankurrc/new_volume/softura/facerec/softura_trained/label_mapping.pkl']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(encoder_mapping, os.path.join(save_path, label_map_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the models by reloading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = joblib.load(os.path.join(save_path, clf_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict_proba(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(X_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy before thresholding: 100.00000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy before thresholding: {:0.5%}\".format(accuracy_score(y_total, predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier Confidence Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_probabilities = np.max(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2\n",
    "thresholded_probabilities = prediction_probabilities < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_indices = np.nonzero(thresholded_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_predicted_labels = predicted_labels.copy()\n",
    "thresholded_predicted_labels[thresholded_indices] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after thresholding with 20.00% confidence: 100.00000%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy after thresholding with {0:0.2%} confidence: {1:0.5%}\".format(threshold, accuracy_score(y_total, thresholded_predicted_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = joblib.load(os.path.join(save_path, label_map_file)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '1',\n",
       " 1: '10',\n",
       " 2: '11',\n",
       " 3: '12',\n",
       " 4: '13',\n",
       " 5: '14',\n",
       " 6: '16',\n",
       " 7: '17',\n",
       " 8: '18',\n",
       " 9: '19',\n",
       " 10: '2',\n",
       " 11: '20',\n",
       " 12: '21',\n",
       " 13: '22',\n",
       " 14: '23',\n",
       " 15: '24',\n",
       " 16: '25',\n",
       " 17: '26',\n",
       " 18: '27',\n",
       " 19: '28',\n",
       " 20: '29',\n",
       " 21: '3',\n",
       " 22: '30',\n",
       " 23: '31',\n",
       " 24: '32',\n",
       " 25: '33',\n",
       " 26: '34',\n",
       " 27: '35',\n",
       " 28: '36',\n",
       " 29: '37',\n",
       " 30: '38',\n",
       " 31: '39',\n",
       " 32: '4',\n",
       " 33: '40',\n",
       " 34: '41',\n",
       " 35: '5',\n",
       " 36: '6',\n",
       " 37: '7',\n",
       " 38: '8',\n",
       " 39: '9'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (dl2)",
   "language": "python",
   "name": "dl2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
